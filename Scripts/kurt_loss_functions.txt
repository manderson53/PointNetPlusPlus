# KURT loss function
# def physics_loss_smoothness(pts_u, logits_u, k=16):
#   # pts_u: [B, N, D] (D may be 4 if you added reflectance)
#   # logits_u: [B, N, C]
# # 1) slice off only the XYZ channels
#   pts_xyz = pts_u[:, :, :3]         # now [B, N, 3]
#   B, N, _  = pts_xyz.shape
# # flatten to [(B*N), 3]
#   xyz = pts_xyz.contiguous().view(B * N, 3)
#   batch_index = torch.arange(B, device=xyz.device).view(B,1).repeat(1,N).view(-1)
#   edge_index = knn_graph(xyz, k, batch=batch_index, loop=False) # [2, E]
# B, N, C = logits_u.shape
# # get softmaxed predictions
#   P = F.softmax(logits_u.view(B, N, -1), dim=2).view(BN, -1)   # [BN, C]
#   i,j = edge_index
#   return F.mse_loss(P[i], P[j])

# def physics_loss_height(pts_u, logits_u, ground_class=1, z_thresh=0.2):
#   """
#   Penalize high 'ground' probability above some Z threshold.
# pts_u  : Tensor of shape [B, 3, N] (x,y,z in channels 0,1,2)
#   logits_u : Tensor of shape [B, N, C]
#   """
#   # 1) pull out the Z coordinate, shape [B, N]
#   #  pts_u is [B,3,N], so pts_u[:,2,:] is [B,N]
#   z = pts_u[:, 2, :].reshape(-1)  # -> [B*N]
# # 2) flatten logits to [BN, C] and softmax
#   B, N, C = logits_u.shape
#   logits_flat = logits_u.reshape(-1, C)    # -> [BN, C]
#   probs   = F.softmax(logits_flat, dim=1)  # -> [B*N, C]
# # 3) grab the ground probability
#   ground_p = probs[:, ground_class]      # -> [B*N]
# # 4) mask out all points below the height threshold
#   mask = (z > z_thresh)
#   if mask.sum() == 0:
#     # no high points at all, so zero penalty
#     return torch.tensor(0., device=pts_u.device)
# # 5) average ground-prob over only the ï¿½too-highï¿½ points
#   return ground_p[mask].mean()


# def physics_loss_refl_smoothness(pts_u, logits, refl, k=16, sigma=0.1):
#   """
#   Reflectance-weighted smoothness:
#    encourages P[i] ï¿½ P[j] when pts[i]ï¿½pts[j] and refl[i]ï¿½refl[j].
#   points:  [B, 3, N]
#   logits:  [B, N, C]
#   refl:   [B, 1, N]  (normalized to [0,1])
#   """
#   # 1) slice off only the XYZ channels
#   pts_xyz = pts_u[:, :, :3]         # now [B, N, 3]
#   B, N, _  = pts_xyz.shape
# # (1) build a k-NN over the XYZ coords
#   xyz = pts_xyz.contiguous().view(B * N, 3)
#   batch = torch.arange(B, device=xyz.device).view(B,1).repeat(1,N).view(-1)
#   edge_index = knn_graph(xyz, k, batch=batch, loop=False) # [2, E]
# # (2) get softmaxed predictions per-point
#   B, N, C = logits.shape
#   P = F.softmax(logits.reshape(-1, C), dim=1)        # [B*N, C]
# # (3) compute a weight per-edge based on reflectance similarity
#   B, N = refl.shape
#   r = refl.contiguous().view(BN)             # [BN]
#   i,j = edge_index
#   w = torch.exp( - ((r[i] - r[j])**2) / (2sigmasigma) )  # [E]
# # (4) weighted MSE on the probabilities
#   return ( w.unsqueeze(1) * (P[i] - P[j]).pow(2) ).mean()